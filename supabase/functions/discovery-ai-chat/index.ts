import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.56.0';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

const openAIApiKey = Deno.env.get('OPENAI_API_KEY');
const supabaseUrl = Deno.env.get('SUPABASE_URL');
const supabaseServiceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');

const supabase = createClient(supabaseUrl!, supabaseServiceRoleKey!);

// Fun√ß√£o para buscar prompt personalizado ou usar padr√£o
async function getCustomPrompt(methodology: string): Promise<string> {
  console.log(`Buscando prompt personalizado para: ${methodology}`);
  
  const { data: customPrompt, error } = await supabase
    .from('custom_prompt_templates')
    .select('prompt_content')
    .eq('scope_type', 'global')
    .eq('prompt_category', 'discovery')
    .eq('template_name', methodology)
    .eq('is_active', true)
    .order('version_number', { ascending: false })
    .maybeSingle();

  if (customPrompt?.prompt_content) {
    console.log('Usando prompt personalizado encontrado');
    return customPrompt.prompt_content;
  }

// Fallback para prompts padr√£o - Humanizados e Contextuais
  const defaultPrompts: Record<string, string> = {
    'Business Model Canvas': `üéØ Voc√™ √© um especialista em Business Model Canvas com personalidade amig√°vel e comunicativa! 

**IMPORTANTE:** Sempre responda de forma HUMANA e CONVERSACIONAL, usando emojis apropriados e linguagem natural. N√£o seja rob√≥tico!

Seu objetivo √© ajudar na descoberta do modelo de neg√≥cio atrav√©s de perguntas inteligentes e contextuais.

**AN√ÅLISE CONTEXTUAL:**
- Se h√° dados das outras etapas (Inception, PBB, Sprint 0), mencione as conex√µes
- Se detectar lacunas importantes, avise proativamente
- Sugira insights baseados no contexto completo da sess√£o

**DEPEND√äNCIAS INTELIGENTES:**
- Para PBB mais assertivo: BMC deve estar bem estruturado
- Para Sprint 0 detalhado: BMC + Inception s√£o importantes

**FORMATO DE RESPOSTA HUMANA:**
Responda conversacionalmente E inclua JSON estruturado quando apropriado:

\`\`\`json
{
  "questions": [
    {
      "category": "proposta_valor",
      "question": "Pergunta espec√≠fica",
      "context": "Por que esta pergunta √© importante"
    }
  ],
  "next_steps": "Pr√≥ximos passos sugeridos",
  "meeting_format": "Como conduzir a reuni√£o"
}
\`\`\``,

    'Inception Workshop': `üë• Voc√™ √© um facilitador experiente de Inception Workshops com energia contagiante!

**IMPORTANTE:** Sempre responda de forma HUMANA e CONVERSACIONAL com emojis e linguagem natural!

**AN√ÅLISE CONTEXTUAL:**
- Se BMC j√° existe, use insights para personas e funcionalidades
- Se Sprint 0 est√° pendente, prepare funda√ß√µes t√©cnicas
- Conecte vis√£o do produto com realidade t√©cnica

**DEPEND√äNCIAS:**
‚úÖ Ideal ter BMC completo para inception mais rico
‚ö†Ô∏è Sem BMC: perguntas mais gen√©ricas sobre vis√£o

Gere perguntas espec√≠ficas focando em vis√£o, objetivos, personas e funcionalidades essenciais, sempre considerando o contexto da sess√£o.`,

    'Product Backlog Building': `üìã Voc√™ √© um Product Owner experiente e estrat√©gico!

**IMPORTANTE:** Sempre responda de forma HUMANA e CONVERSACIONAL!

**AN√ÅLISE DE DEPEND√äNCIAS CR√çTICA:**
- ‚úÖ **Com BMC + Inception:** Backlog super estruturado com √©picos claros
- ‚ö†Ô∏è **Sem BMC:** Avise que BMC ajudaria muito na prioriza√ß√£o
- ‚ö†Ô∏è **Sem Inception:** Mencione que personas/vis√£o s√£o importantes

**INTELIG√äNCIA CONTEXTUAL:**
- Use dados de BMC para estruturar √©picos
- Use personas do Inception para user stories
- Prepare base para Sprint 0 t√©cnico

Gere perguntas focando em √©picos, funcionalidades, prioriza√ß√£o e estimativas, mas sempre considerando o contexto completo.`,

    'Sprint 0': `üöÄ Voc√™ √© um Scrum Master experiente e organizador!

**IMPORTANTE:** Sempre responda de forma HUMANA e CONVERSACIONAL!

**AN√ÅLISE DE DEPEND√äNCIAS PARA SPRINT 0:**
- ‚úÖ **Com BMC + Inception + PBB:** Sprint 0 super detalhado e assertivo!
- ‚ö†Ô∏è **Faltando BMC:** Alerte que defini√ß√µes de neg√≥cio ajudam muito
- ‚ö†Ô∏è **Faltando Inception:** Mencione que vis√£o t√©cnica fica limitada
- ‚ö†Ô∏è **Faltando PBB:** Dificulta planejamento de √©picos t√©cnicos

**INTELIG√äNCIA CONTEXTUAL:**
- Use complexidade do produto (BMC) para sugerir tecnologias
- Use personas (Inception) para definir requisitos n√£o-funcionais
- Use √©picos (PBB) para estruturar arquitetura

Gere perguntas sobre ambiente, ferramentas, padr√µes e processos, sempre considerando o contexto completo da sess√£o.`
  };

  console.log('Usando prompt padr√£o');
  return defaultPrompts[methodology] || defaultPrompts['Business Model Canvas'];
}

serve(async (req) => {
  console.log(`${new Date().toISOString()} - Request received: ${req.method}`);

  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { sessionId, message, currentStage, conversationHistory = [] } = await req.json();
    console.log(`Processing request for session: ${sessionId}, stage: ${currentStage}`);

    if (!sessionId || !message) {
      throw new Error('SessionId e message s√£o obrigat√≥rios');
    }

    // Buscar dados completos da sess√£o para contexto
    const { data: sessionData, error: sessionError } = await supabase
      .from('smart_discovery_sessions')
      .select('*')
      .eq('id', sessionId)
      .single();

    if (sessionError) {
      console.error('Erro ao buscar sess√£o:', sessionError);
      throw new Error('Sess√£o n√£o encontrada');
    }

    // Mapear stage atual para metodologia
    const stageToMethodology: Record<string, string> = {
      'business_canvas': 'Business Model Canvas',
      'inception': 'Inception Workshop', 
      'pbb': 'Product Backlog Building',
      'sprint0': 'Sprint 0'
    };

    const methodology = stageToMethodology[currentStage] || 'Business Model Canvas';
    
    // Buscar prompt personalizado
    const systemPrompt = await getCustomPrompt(methodology);
    
    // Preparar contexto estruturado da sess√£o
    const sessionContext = {
      session_name: sessionData.session_name,
      current_stage: sessionData.current_stage,
      business_canvas_data: sessionData.business_canvas_data || {},
      inception_data: sessionData.inception_data || {},
      pbb_data: sessionData.pbb_data || {},
      sprint0_data: sessionData.sprint0_data || {}
    };

    // Substituir placeholders no prompt
    const contextualizedPrompt = systemPrompt
      .replace('{session_context}', JSON.stringify(sessionContext, null, 2))
      .replace('{conversation_history}', JSON.stringify(conversationHistory.slice(-10), null, 2));

    // Preparar mensagens para OpenAI (sem limite de 6 mensagens)
    const messages = [
      { role: 'system', content: contextualizedPrompt },
      ...conversationHistory.map((msg: any) => ({
        role: msg.role,
        content: msg.content
      })),
      { role: 'user', content: message }
    ];

    console.log(`Enviando ${messages.length} mensagens para OpenAI`);

    // Chamar OpenAI com fallback e timeout
    let aiResponse: string;
    const models = ['gpt-5-2025-08-07', 'gpt-4.1-2025-04-14'];
    
    for (let i = 0; i < models.length; i++) {
      const model = models[i];
      console.log(`Tentando modelo: ${model}`);
      
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 15000); // 15s timeout
        
        const requestBody = {
          model: model,
          messages: messages,
          ...(model.startsWith('gpt-5') || model.includes('gpt-4.1') 
            ? { max_completion_tokens: 2000 } 
            : { max_tokens: 2000, temperature: 0.7 }
          )
        };
        
        console.log('Enviando requisi√ß√£o para OpenAI:', { model, messageCount: messages.length });
        
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${openAIApiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(requestBody),
          signal: controller.signal
        });

        clearTimeout(timeoutId);

        if (!response.ok) {
          const errorData = await response.text();
          console.error(`Erro do modelo ${model}:`, errorData);
          
          if (i === models.length - 1) {
            throw new Error(`Todos os modelos falharam. √öltimo erro: ${response.status}`);
          }
          continue; // Tenta pr√≥ximo modelo
        }

        const data = await response.json();
        
        if (!data.choices || !data.choices[0] || !data.choices[0].message) {
          console.error('Resposta inv√°lida da OpenAI:', data);
          if (i === models.length - 1) {
            throw new Error('Resposta inv√°lida da OpenAI');
          }
          continue;
        }
        
        aiResponse = data.choices[0].message.content;
        
        if (!aiResponse || aiResponse.trim().length === 0) {
          console.error('Resposta vazia da OpenAI');
          if (i === models.length - 1) {
            throw new Error('Resposta vazia da OpenAI');
          }
          continue;
        }
        
        console.log(`Sucesso com modelo ${model}, resposta recebida com ${aiResponse.length} caracteres`);
        break; // Sucesso, sai do loop
        
      } catch (error) {
        console.error(`Erro com modelo ${model}:`, error);
        if (i === models.length - 1) {
          throw error; // Re-throw se foi o √∫ltimo modelo
        }
        // Continua para o pr√≥ximo modelo
      }
    }

    console.log('Resposta da IA recebida, extraindo dados estruturados...');

    // Extrair dados estruturados da resposta
    let extractedData = null;
    const jsonMatch = aiResponse.match(/```json\n(.*?)\n```/s);
    
    if (jsonMatch) {
      try {
        extractedData = JSON.parse(jsonMatch[1]);
        console.log('Dados estruturados extra√≠dos:', extractedData);
      } catch (parseError) {
        console.log('Erro ao fazer parse do JSON, continuando sem dados estruturados');
      }
    }

    // Salvar dados no campo espec√≠fico baseado no stage
    if (extractedData) {
      const updateData: any = {};
      
      if (currentStage === 'business_canvas') {
        updateData.business_canvas_data = extractedData;
      } else if (currentStage === 'inception') {
        updateData.inception_data = extractedData;
      } else if (currentStage === 'pbb') {
        updateData.pbb_data = extractedData;
      } else if (currentStage === 'sprint0') {
        updateData.sprint0_data = extractedData;
      }

      if (Object.keys(updateData).length > 0) {
        const { error: updateError } = await supabase
          .from('smart_discovery_sessions')
          .update(updateData)
          .eq('id', sessionId);

        if (updateError) {
          console.error('Erro ao salvar dados estruturados:', updateError);
        } else {
          console.log('Dados estruturados salvos com sucesso');
        }
      }
    }

    return new Response(JSON.stringify({
      response: aiResponse,
      extractedData,
      sessionContext
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('Erro no processamento:', error);
    return new Response(JSON.stringify({
      error: error.message,
      details: 'Erro interno do servidor'
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});